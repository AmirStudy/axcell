{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Papers with Code ML papers dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/paperswithcode/paper-extractor\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sota_extractor2.data.paper_collection import PaperCollection\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path(\"data/arxiv\")\n",
    "PICKLE_PATH = Path(\"data/pc.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The dataset was created by parsing 75K arXiv papers related to machine learning. Due to parsing errors, the dataset contains texts and tables extracted from 56K papers. \n",
    "```\n",
    ".\n",
    "└── arxiv\n",
    "    ├── papers\n",
    "    │   ├── 0709\n",
    "    │   │   ├── 0709.1667\n",
    "    │   │   │   ├── text.json\n",
    "    │   │   │   ├── metadata.json\n",
    "    │   │   │   ├── table_01.csv\n",
    "    │   │   │   ...\n",
    "    │   │   ...\n",
    "    │   ...\n",
    "    └── structure-annotations.json\n",
    "```\n",
    "\n",
    "`text.json` files contains papers' content organized into sections. `metadata.json` list tables and their captions found in a given paper. `table_xx.csv` contains data of a given table (nested tables are flattened). We provide a simple API to load and access the dataset. Due to large number of papers it is recommended to load the dataset in parallel (default uses number of processes equal to number of CPU cores) and store it in a pickle file. Set `jobs=1` to disable multiprocessing. PaperCollection is a wrapper for `list` of papers with additional functions added for convenience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 58s, sys: 12.4 s, total: 5min 11s\n",
      "Wall time: 7min 28s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "56696"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time pc = PaperCollection.from_files(DATA_PATH)\n",
    "len(pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.to_pickle(PICKLE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 11s, sys: 9.39 s, total: 3min 20s\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "#%time pc = PaperCollection.from_pickle(PICKLE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The path is searched recursively for papers, so it is easy to specify smaller dataset to play with. In this case, however, a path to `structure-annotations.json` file needs to be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.35 s, sys: 2.08 s, total: 4.43 s\n",
      "Wall time: 8.62 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "555"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%time pc_small = PaperCollection.from_files(DATA_PATH / \"papers\" / \"1602\", annotations_path=DATA_PATH / \"structure-annotations.json\")\n",
    "#len(pc_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables\n",
    "Each `Paper` contains `text` and `tables` fields. Tables can be displayed with color-coded labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>body{margin:0;padding:0;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}code{font-family:source-code-pro,Menlo,Monaco,Consolas,Courier New,monospace}.tableWrapper{-overflow:auto}.tableWrapper .model-params{background-color:#209cee;color:rgba(0,0,0,.7)}.tableWrapper .table-meta{background-color:#fff3c5;color:rgba(0,0,0,.7)}.tableWrapper .model-best{background-color:#ff3860;color:rgba(0,0,0,.7)}.tableWrapper .model-competing{background-color:#ffdd57;color:rgba(0,0,0,.7)}.tableWrapper .model-paper{background-color:#ff3860;color:#fff}.tableWrapper .dataset-sub{background-color:#23d160;color:#fff}.tableWrapper .dataset-metric{background-color:#209cee;color:#fff}.tableWrapper .dataset{background-color:#02bd43;color:#fff}.tableWrapper .trash{background-color:#363636;color:#f5f5f5}.tableWrapper .wtf{background-color:#f0f;color:#f5f5f5}.tableWrapper .dataset-task{background-color:#77ecdd;color:rgba(0,0,0,.7)}.tableWrapper .dataset-paper{background-color:#e4ffee;color:rgba(0,0,0,.7)}.tableWrapper td.focused-cell{outline:2px solid #9ecaed;border-radius:7px;box-shadow:0 0 10px #9ecaed}div.form-group>input.form-control.input-sm{border-radius:2px;font-size:.75rem;background-color:#fff;color:#363636;box-shadow:inset 0 1px 2px rgba(10,10,10,.1);max-width:100%;width:100%;height:2.25em;padding:calc(.375em - 1px) calc(.625em - 1px);position:relative;border:1px solid #b5b5b5}div.form-group>input.form-control.input-sm:focus{border-color:#3273dc;box-shadow:0 0 0 .125em rgba(50,115,220,.25)}\n",
       "</style>\n",
       "\n",
       "<div class=\"tableWrapper\">\n",
       "<table>\n",
       "<tr>\n",
       "<td class=\"table-meta\">Model</td>\n",
       "<td class=\"model-params\">d</td>\n",
       "<td class=\"model-params\">|θ|M</td>\n",
       "<td class=\"dataset-sub\">Train</td>\n",
       "<td class=\"dataset-sub\">Test</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">Classifier with handcrafted features [12]</td>\n",
       "<td class=\"\">-</td>\n",
       "<td class=\"\">-</td>\n",
       "<td class=\"\">99.7</td>\n",
       "<td class=\"\">78.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">LSTM encoders [12]</td>\n",
       "<td class=\"\">300</td>\n",
       "<td class=\"\">3.0M</td>\n",
       "<td class=\"\">83.9</td>\n",
       "<td class=\"\">80.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">Dependency Tree CNN encoders [13]</td>\n",
       "<td class=\"\">300</td>\n",
       "<td class=\"\">3.5M</td>\n",
       "<td class=\"\">83.3</td>\n",
       "<td class=\"\">82.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">SPINN-PI encoders [14]</td>\n",
       "<td class=\"\">300</td>\n",
       "<td class=\"\">3.7M</td>\n",
       "<td class=\"\">89.2</td>\n",
       "<td class=\"\">83.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-paper\">NSE</td>\n",
       "<td class=\"\">300</td>\n",
       "<td class=\"\">3.4M</td>\n",
       "<td class=\"\">86.2</td>\n",
       "<td class=\"\">84.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-paper\">MMA-NSE</td>\n",
       "<td class=\"\">300</td>\n",
       "<td class=\"\">6.3M</td>\n",
       "<td class=\"\">87.1</td>\n",
       "<td class=\"\">84.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">LSTM attention [15]</td>\n",
       "<td class=\"\">100</td>\n",
       "<td class=\"\">242K</td>\n",
       "<td class=\"\">85.4</td>\n",
       "<td class=\"\">82.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">LSTM word-by-word attention [15]</td>\n",
       "<td class=\"\">100</td>\n",
       "<td class=\"\">252K</td>\n",
       "<td class=\"\">85.3</td>\n",
       "<td class=\"\">83.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-best\">MMA-NSE attention</td>\n",
       "<td class=\"\">300</td>\n",
       "<td class=\"\">6.5M</td>\n",
       "<td class=\"\">86.9</td>\n",
       "<td class=\"\">85.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">mLSTM word-by-word attention [16]</td>\n",
       "<td class=\"\">300</td>\n",
       "<td class=\"\">1.9M</td>\n",
       "<td class=\"\">92.0</td>\n",
       "<td class=\"\">86.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">LSTMN with deep attention fusion [17]</td>\n",
       "<td class=\"\">450</td>\n",
       "<td class=\"\">3.4M</td>\n",
       "<td class=\"\">89.5</td>\n",
       "<td class=\"\">86.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">Decomposable attention model [18]</td>\n",
       "<td class=\"\">200</td>\n",
       "<td class=\"\">582K</td>\n",
       "<td class=\"\">90.5</td>\n",
       "<td class=\"\">86.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">Full tree matching NTI-SLSTM-LSTM global attention [19]</td>\n",
       "<td class=\"\">300</td>\n",
       "<td class=\"\">3.2M</td>\n",
       "<td class=\"\">88.5</td>\n",
       "<td class=\"\">87.3</td>\n",
       "</tr>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paper = pc.get_by_id('1607.04315')\n",
    "table = paper.tables[0]\n",
    "table.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>body{margin:0;padding:0;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}code{font-family:source-code-pro,Menlo,Monaco,Consolas,Courier New,monospace}.tableWrapper{-overflow:auto}.tableWrapper .model-params{background-color:#209cee;color:rgba(0,0,0,.7)}.tableWrapper .table-meta{background-color:#fff3c5;color:rgba(0,0,0,.7)}.tableWrapper .model-best{background-color:#ff3860;color:rgba(0,0,0,.7)}.tableWrapper .model-competing{background-color:#ffdd57;color:rgba(0,0,0,.7)}.tableWrapper .model-paper{background-color:#ff3860;color:#fff}.tableWrapper .dataset-sub{background-color:#23d160;color:#fff}.tableWrapper .dataset-metric{background-color:#209cee;color:#fff}.tableWrapper .dataset{background-color:#02bd43;color:#fff}.tableWrapper .trash{background-color:#363636;color:#f5f5f5}.tableWrapper .wtf{background-color:#f0f;color:#f5f5f5}.tableWrapper .dataset-task{background-color:#77ecdd;color:rgba(0,0,0,.7)}.tableWrapper .dataset-paper{background-color:#e4ffee;color:rgba(0,0,0,.7)}.tableWrapper td.focused-cell{outline:2px solid #9ecaed;border-radius:7px;box-shadow:0 0 10px #9ecaed}div.form-group>input.form-control.input-sm{border-radius:2px;font-size:.75rem;background-color:#fff;color:#363636;box-shadow:inset 0 1px 2px rgba(10,10,10,.1);max-width:100%;width:100%;height:2.25em;padding:calc(.375em - 1px) calc(.625em - 1px);position:relative;border:1px solid #b5b5b5}div.form-group>input.form-control.input-sm:focus{border-color:#3273dc;box-shadow:0 0 0 .125em rgba(50,115,220,.25)}\n",
       "</style>\n",
       "\n",
       "<div class=\"tableWrapper\">\n",
       "<table>\n",
       "<tr>\n",
       "<td class=\"\">Tag</td>\n",
       "<td class=\"\">description</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-best\">model-best</td>\n",
       "<td class=\"\">model that has results that author most likely would like to have exposed</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-paper\">model-paper</td>\n",
       "<td class=\"\">an example of a generic model, (like LSTM)</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">model-competing</td>\n",
       "<td class=\"\">model from another paper used for comparison</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"dataset-task\">dataset-task</td>\n",
       "<td class=\"\">Task</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"dataset\">dataset</td>\n",
       "<td class=\"\">Dataset</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"dataset-sub\">dataset-sub</td>\n",
       "<td class=\"\">Subdataset</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"dataset-metric\">dataset-metric</td>\n",
       "<td class=\"\">Metric</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-params\">model-params</td>\n",
       "<td class=\"\">Params, f.e., number of layers or inference time</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"table-meta\">table-meta</td>\n",
       "<td class=\"\">Cell describing other header cells</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"trash\">trash</td>\n",
       "<td class=\"\">Parsing erros</td>\n",
       "</tr>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PaperCollection.cells_gold_tags_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table's data is stored in `.df` pandas `DataFrame`. Each cell contains its content `value`, annotated `gold_tags` and references `refs` to other papers. Most of the references were normalized across all papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cell(value='SPINN-PI encoders [14]', gold_tags='model-competing', refs=['xxref-23c141141f4f63c061d3cce14c71893959af5721'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.df.iloc[4,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, each table contains `gold_tags` describing what is the content of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sota'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.gold_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Content\n",
    "Papers' content is represented using elastic search document classes (can be easily `save()`'ed to an existing elastic search instance). Each `text` contains `title`, `abstract`, and 'authors'. Paper's text is split into `fragments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abstract We present a memory augmented neural network for natural language understanding: Neural Semantic Encoders. NSE is equipped with a novel memory update rule and has a variable sized encoding memory that evolves over time and maintains the understanding of input sequences through read , compose and write operations. NSE can also access 1 xxanchor-x1-2f1 multiple and shared memories. In this paper, we demonstrated the effectiveness and the flexibility of NSE on five different natural language tasks: natural language inference, question answering, sentence classification, document sentiment analysis and machine translation where NSE achieved state-of-the-art performance when evaluated on publically available benchmarks. For example, our shared-memory model showed an encouraging result on neural machine translation, improving an attention-based baseline by approximately 1.0 BLEU.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper.text.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1 xxanchor-x1-10001 Introduction"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2 xxanchor-x1-20002 Related Work"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3 xxanchor-x1-30003 Proposed Approach"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3.1 xxanchor-x1-40003.1 Read, Compose and Write"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3.2 xxanchor-x1-50003.2 Shared and Multiple Memory Accesses"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4 xxanchor-x1-60004 Experiments"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4.1 xxanchor-x1-70004.1 Natural Language Inference"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4.2 xxanchor-x1-80004.2 Answer Sentence Selection"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4.3 xxanchor-x1-90004.3 Sentence Classification"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4.4 xxanchor-x1-100004.4 Document Sentiment Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4.5 xxanchor-x1-110004.5 Machine Translation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "5.1 xxanchor-x1-130005.1 Memory Access and Compositionality"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "6 xxanchor-x1-140006 Conclusion"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "xxanchor-x1-150006 Acknowledgments"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "xxanchor-x1-160006 References"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "A xxanchor-x1-17000A Step-by-step visualization of memory states in NSE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paper.text.print_toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# 4.5 xxanchor-x1-110004.5 Machine Translation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Lastly, we conducted an experiment on neural machine translation (NMT). The NMT problem is mostly defined within the encoder-decoder framework [ xxref-4b9b7eed30feee37db3452b74503d0db9f163074 , xxref-0b544dfe355a5070b60986319a3f51fb45d1348e , xxref-39dba6f22d72853561a4ed684be265e179a39e4f ]. The encoder provides the semantic and syntactic information about the source sentences to the decoder and the decoder generates the target sentences by conditioning on this information and its partially produced translation. For an efficient encoding, the attention-based NTM was introduced [ xxref-071b16f25117fb6133480c6259227d54fc2a5ea0 ]."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "11000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "For NTM, we implemented three different models. The first model is a baseline model and is similar to the one proposed in [ xxref-071b16f25117fb6133480c6259227d54fc2a5ea0 ] (RNNSearch). This model (LSTM-LSTM) has two LSTM for the encoder/decoder and has the soft attention neural net, which attends over the source sentence and constructs a focused encoding vector for each target word. The second model is an NSE-LSTM encoder-decoder which encodes the source sentence with NSE and generates the targets with the LSTM network by using the NSE output states and the attention network. The last model is an NSE-NSE setup, where the encoding part is the same as the NSE-LSTM while the decoder NSE now uses the output state and has an access to the encoder memory, i.e., the encoder and the decoder NSEs access a shared memory. The memory is encoded by the first NSEs and then read/written by the decoder NSEs. We used the English-German translation corpus from the IWSLT 2014 evaluation campaign [ xxref-c64d27b122d5b6ef0be135e63df05c3b24bd80c5 ]. The corpus consists of sentence-aligned translation of TED talks. The data was pre-processed and lowercased with the Moses toolkit. 9 xxanchor-x1-11001f9 We merged the dev2010 and dev2012 sets for development and the tst2010, tst2011 and tst2012 sets for test data 10 xxanchor-x1-11002f10 . Sentence pairs with length longer than 25 words were filtered out. This resulted in 110,439/4,998/4,793 pairs for train/dev/test sets. We kept the most frequent 25,000 words for the German dictionary. The English dictionary has 51,821 words. The 300-D Glove 840B vectors were used for embedding the words in the source sentence whereas a lookup embedding layer was used for the target German words. Note that the word embeddings are usually optimized along with the NMT models. However, for the evaluation purpose we in this experiment do not optimize the English word embeddings. Besides, we do not use a beam search to generate the target sentences."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "11001"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "xxanchor-x1-110032 Figure 2: Word association or composition graphs produced by NSE memory access. The directed arcs connect the words that are composed via compose module. The source nodes are input words and the destination nodes (pointed by the arrows) correspond to the accessed memory slots. < S > denotes the beginning of sequence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "11002"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The LSTM encoder/decoders have two layers with 300 units. The NSE read/write modules are two one-layer LSTM with the same number of units as the LSTM encoder/decoders. This ensures that the number of parameters of the models is roughly the equal. The models were trained to minimize word-level cross entropy loss and were regularized by 20% input dropouts and the 30% output dropouts. We set the batch size to 128, the initial learning rate to 1e-3 for LSTM-LSTM and 3e-4 for the other models and l 2 regularizer strength to 3e-5, and train each model for 40 epochs. We report BLEU score for each models. 11 xxanchor-x1-11004f11"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "11003"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Table xxref-x1-100035 reports our results. The baseline LSTM-LSTM encoder-decoder (with attention) obtained 17.02 BLEU on the test set. The NSE-LSTM improved the baseline slightly. Given this very small improvement of the NSE-LSTM, it is unclear whether the NSE encoder is helpful in NMT. However, if we replace the LSTM decoder with another NSE and introduce the shared memory access to the encoder-decoder model (NSE-NSE), we improve the baseline result by almost 1.0 BLEU. The NSE-NSE model also yields an increasing BLEU score on dev set. The result demonstrates that the attention-based NMT systems can be improved by a shared-memory encoder-decoder model. In addition, memory-based NMT systems should perform well on translation of long sequences by preserving long term dependencies."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "11004"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paper.text.print_section(\"Machine Translation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fragments can be accessed separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# 1 xxanchor-x1-10001 Introduction,\n",
       "Recently several studies have explored ways of extending the neural networks with an external memory [ xxref-6eedf0a4fe861335f7f7664c14de7f71c00b7932 – xxref-950ebd31505dfc0733c391ad9b7a16571c46002e ]. Unlike LSTM, the short term memories and the training parameters of such a neural network are no longer coupled and can be adapted. In this paper we propose a novel class of memory augmented neural networks called Neural Semantic Encoders (NSE) for natural language understanding. NSE offers several desirable properties. NSE has a variable sized encoding memory which allows the model to access entire input sequence during the reading process; therefore efficiently delivering long-term dependencies over time. The encoding memory evolves over time and maintains the memory of the input sequence through read , compose and write operations. NSE sequentially processes the input and supports word compositionality inheriting both temporal and hierarchical nature of human language. NSE can read from and write to a set of relevant encoding memories simultaneously or multiple NSEs can access a shared encoding memory effectively supporting knowledge and representation sharing. NSE is flexible, robust and suitable for practical NLU tasks and can be trained easily by any gradient descent optimizer.<Fragment(meta.id=1607.04315_1001, order=1001)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper.text.fragments[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
