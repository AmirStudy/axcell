{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Papers with Code ML papers dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/github/mkardas/paper-extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sota_extractor2.data.paper_collection import PaperCollection\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path(\"/home/ubuntu/pwc/arxiv-s3/arxiv\")\n",
    "PICKLE_PATH = Path(\"/home/ubuntu/pwc/pc-pickle.pkl\")\n",
    "#DATA_PATH = Path(\"/home/ubuntu/pwc/arxiv-pwc/arxiv\")\n",
    "#PICKLE_PATH = Path(\"/home/ubuntu/pwc/pc-pickle-fast.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The dataset was created by parsing 75K arXiv papers related to machine learning. Due to parsing errors, the dataset contains texts and tables extracted from 56K papers. \n",
    "```\n",
    ".\n",
    "└── arxiv\n",
    "    ├── texts\n",
    "    │   └── 0709\n",
    "    │       ├── 0709.1667.json\n",
    "    │       ...\n",
    "    │   ...\n",
    "    ├── tables\n",
    "    │   └── 0709\n",
    "    │       ├── 0709.1667\n",
    "    │       │   ├── metadata.json\n",
    "    │       │   ├── table_01.csv\n",
    "    │       │   ...\n",
    "    │       ...\n",
    "    │   ...\n",
    "    └── structure-annotations.json\n",
    "```\n",
    "\n",
    "`texts` directory contains `.json` files with papers' content organized into sections. `metadata.json` list tables and their captions found in a given paper. `table_xx.csv` contains data of a given table (nested tables are flattened). We provide a simple API to load and access the dataset. Due to large number of papers it is recommended to load the dataset in parallel (default uses number of processes equal to number of CPU cores) and store it in a pickle file. Set `jobs=1` to disable multiprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 10s, sys: 10.4 s, total: 3min 20s\n",
      "Wall time: 7min 16s\n"
     ]
    }
   ],
   "source": [
    "%time pc = PaperCollection.from_files(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.to_pickle(PICKLE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.48 s, sys: 144 ms, total: 3.63 s\n",
      "Wall time: 3.58 s\n"
     ]
    }
   ],
   "source": [
    "%time pc = PaperCollection.from_pickle(PICKLE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PaperCollection is a wrapper for `list` of papers with additional functions added for convenience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56696"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables\n",
    "Each `Paper` contains `text` and `tables` fields. Tables can be displayed with color-coded labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>body{margin:0;padding:0;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen,Ubuntu,Cantarell,Fira Sans,Droid Sans,Helvetica Neue,sans-serif;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale}code{font-family:source-code-pro,Menlo,Monaco,Consolas,Courier New,monospace}.tableWrapper{-overflow:auto}.tableWrapper .model-params{background-color:#209cee;color:rgba(0,0,0,.7)}.tableWrapper .table-meta{background-color:#fff3c5;color:rgba(0,0,0,.7)}.tableWrapper .model-best{background-color:#ff3860;color:rgba(0,0,0,.7)}.tableWrapper .model-competing{background-color:#ffdd57;color:rgba(0,0,0,.7)}.tableWrapper .model-paper{background-color:#ff3860;color:#fff}.tableWrapper .dataset-sub{background-color:#23d160;color:#fff}.tableWrapper .dataset-metric{background-color:#209cee;color:#fff}.tableWrapper .dataset{background-color:#02bd43;color:#fff}.tableWrapper .trash{background-color:#363636;color:#f5f5f5}.tableWrapper .wtf{background-color:#f0f;color:#f5f5f5}.tableWrapper .dataset-task{background-color:#77ecdd;color:rgba(0,0,0,.7)}.tableWrapper .dataset-paper{background-color:#e4ffee;color:rgba(0,0,0,.7)}.tableWrapper td.focused-cell{outline:2px solid #9ecaed;border-radius:7px;box-shadow:0 0 10px #9ecaed}div.form-group>input.form-control.input-sm{border-radius:2px;font-size:.75rem;background-color:#fff;color:#363636;box-shadow:inset 0 1px 2px rgba(10,10,10,.1);max-width:100%;width:100%;height:2.25em;padding:calc(.375em - 1px) calc(.625em - 1px);position:relative;border:1px solid #b5b5b5}div.form-group>input.form-control.input-sm:focus{border-color:#3273dc;box-shadow:0 0 0 .125em rgba(50,115,220,.25)}\n",
       "</style>\n",
       "\n",
       "<div class=\"tableWrapper\">\n",
       "<table>\n",
       "<tr>\n",
       "<td class=\"table-meta\">Model</td>\n",
       "<td class=\"model-params\">d</td>\n",
       "<td class=\"model-params\">|Î¸|M</td>\n",
       "<td class=\"dataset-sub\">Train</td>\n",
       "<td class=\"dataset-sub\">Test</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">Classifier with handcrafted features [12]</td>\n",
       "<td class=\"\">-</td>\n",
       "<td class=\"\">-</td>\n",
       "<td class=\"\">99.7</td>\n",
       "<td class=\"\">78.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">LSTM encoders [12]</td>\n",
       "<td class=\"\">300</td>\n",
       "<td class=\"\">3.0M</td>\n",
       "<td class=\"\">83.9</td>\n",
       "<td class=\"\">80.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">Dependency Tree CNN encoders [13]</td>\n",
       "<td class=\"\">300</td>\n",
       "<td class=\"\">3.5M</td>\n",
       "<td class=\"\">83.3</td>\n",
       "<td class=\"\">82.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">SPINN-PI encoders [14]</td>\n",
       "<td class=\"\">300</td>\n",
       "<td class=\"\">3.7M</td>\n",
       "<td class=\"\">89.2</td>\n",
       "<td class=\"\">83.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-paper\">NSE</td>\n",
       "<td class=\"\">300</td>\n",
       "<td class=\"\">3.4M</td>\n",
       "<td class=\"\">86.2</td>\n",
       "<td class=\"\">84.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-paper\">MMA-NSE</td>\n",
       "<td class=\"\">300</td>\n",
       "<td class=\"\">6.3M</td>\n",
       "<td class=\"\">87.1</td>\n",
       "<td class=\"\">84.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">LSTM attention [15]</td>\n",
       "<td class=\"\">100</td>\n",
       "<td class=\"\">242K</td>\n",
       "<td class=\"\">85.4</td>\n",
       "<td class=\"\">82.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">LSTM word-by-word attention [15]</td>\n",
       "<td class=\"\">100</td>\n",
       "<td class=\"\">252K</td>\n",
       "<td class=\"\">85.3</td>\n",
       "<td class=\"\">83.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-best\">MMA-NSE attention</td>\n",
       "<td class=\"\">300</td>\n",
       "<td class=\"\">6.5M</td>\n",
       "<td class=\"\">86.9</td>\n",
       "<td class=\"\">85.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">mLSTM word-by-word attention [16]</td>\n",
       "<td class=\"\">300</td>\n",
       "<td class=\"\">1.9M</td>\n",
       "<td class=\"\">92.0</td>\n",
       "<td class=\"\">86.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">LSTMN with deep attention fusion [17]</td>\n",
       "<td class=\"\">450</td>\n",
       "<td class=\"\">3.4M</td>\n",
       "<td class=\"\">89.5</td>\n",
       "<td class=\"\">86.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">Decomposable attention model [18]</td>\n",
       "<td class=\"\">200</td>\n",
       "<td class=\"\">582K</td>\n",
       "<td class=\"\">90.5</td>\n",
       "<td class=\"\">86.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td class=\"model-competing\">Full tree matching NTI-SLSTM-LSTM global attention [19]</td>\n",
       "<td class=\"\">300</td>\n",
       "<td class=\"\">3.2M</td>\n",
       "<td class=\"\">88.5</td>\n",
       "<td class=\"\">87.3</td>\n",
       "</tr>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paper = pc.get_by_id('1607.04315')\n",
    "table = paper.tables[0]\n",
    "table.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table's data is stored in `.df` pandas `DataFrame`. Each cell contains its content `value`, annotated `gold_tags` and references `refs` to other papers. Most of the references were normalized across all papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cell(value='SPINN-PI encoders [14]', gold_tags='model-competing', refs=['xxref-XBowmanGRGMP16'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.df.iloc[4,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, each table contains `gold_tags` describing what is the content of the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3e23c0e16ba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgold_tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'table' is not defined"
     ]
    }
   ],
   "source": [
    "table.gold_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Content\n",
    "Papers' content is represented using elastic search document classes (can be easily `save()`'ed to an existing elastic search instance). Each `text` contains `title`, `abstract`, and 'authors'. Paper's text is split into `fragments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Abstract We present a memory augmented neural network for natural language understanding: Neural Semantic Encoders. NSE is equipped with a novel memory update rule and has a variable sized encoding memory that evolves over time and maintains the understanding of input sequences through read , compose and write operations. NSE can also access 1 xxanchor-x1-2f1 multiple and shared memories. In this paper, we demonstrated the effectiveness and the flexibility of NSE on five different natural language tasks: natural language inference, question answering, sentence classification, document sentiment analysis and machine translation where NSE achieved state-of-the-art performance when evaluated on publically available benchmarks. For example, our shared-memory model showed an encouraging result on neural machine translation, improving an attention-based baseline by approximately 1.0 BLEU.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper.text.abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1 xxanchor-x1-10001 Introduction"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "2 xxanchor-x1-20002 Related Work"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3 xxanchor-x1-30003 Proposed Approach"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3.1 xxanchor-x1-40003.1 Read, Compose and Write"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "3.2 xxanchor-x1-50003.2 Shared and Multiple Memory Accesses"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4 xxanchor-x1-60004 Experiments"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4.1 xxanchor-x1-70004.1 Natural Language Inference"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4.2 xxanchor-x1-80004.2 Answer Sentence Selection"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4.3 xxanchor-x1-90004.3 Sentence Classification"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4.4 xxanchor-x1-100004.4 Document Sentiment Analysis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "4.5 xxanchor-x1-110004.5 Machine Translation"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "5.1 xxanchor-x1-130005.1 Memory Access and Compositionality"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "6 xxanchor-x1-140006 Conclusion"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "xxanchor-x1-150006 Acknowledgments"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "xxanchor-x1-160006 References"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "A xxanchor-x1-17000A Step-by-step visualization of memory states in NSE"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paper.text.print_toc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# 1 xxanchor-x1-10001 Introduction,\n",
       "Recently several studies have explored ways of extending the neural networks with an external memory [ xxref-Xgraves2014neural – xxref-Xgrefenstette2015learning ]. Unlike LSTM, the short term memories and the training parameters of such a neural network are no longer coupled and can be adapted. In this paper we propose a novel class of memory augmented neural networks called Neural Semantic Encoders (NSE) for natural language understanding. NSE offers several desirable properties. NSE has a variable sized encoding memory which allows the model to access entire input sequence during the reading process; therefore efficiently delivering long-term dependencies over time. The encoding memory evolves over time and maintains the memory of the input sequence through read , compose and write operations. NSE sequentially processes the input and supports word compositionality inheriting both temporal and hierarchical nature of human language. NSE can read from and write to a set of relevant encoding memories simultaneously or multiple NSEs can access a shared encoding memory effectively supporting knowledge and representation sharing. NSE is flexible, robust and suitable for practical NLU tasks and can be trained easily by any gradient descent optimizer.<Fragment(meta.id=1607.04315_1001, order=1001)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper.text.fragments[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper.text.print_section(\"Machine Translation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
